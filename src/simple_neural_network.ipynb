{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simple Fully Connected Neural Network\n",
   "id": "8eea01aaa33cfa95"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a fully connected neural network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size: int, num_classes:int) -> None:\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "ff7556970ec570e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set a device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "351111ce9bdf271d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define hyper-parameters\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "load_model = False\n",
    "checkpoint_path = '../checkpoints/nn'"
   ],
   "id": "ed86a0d1f50ec9d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load data\n",
    "train_dataset = datasets.MNIST(root='../dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='../dataset/', train=False, transform=transforms.ToTensor(), download=True)"
   ],
   "id": "4dc8ca956dec5374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "f823bf65693103f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "# loss functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "8da8c250d677084e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:52:15.410686Z",
     "start_time": "2024-07-26T11:52:15.379260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ],
   "id": "402a4fadac6f69d1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if load_model:\n",
    "    load_model(torch.load(f\"{checkpoint_path}/checkpoint_1.pth.tar\"))\n",
    "    \n",
    "# put the model in training mode\n",
    "model.train()"
   ],
   "id": "2f992335077c800d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # set the data to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # backward\n",
    "        optimizer.zero_grad() # set all gradients to zero for each batch to avoid storing batch forward calculation\n",
    "        loss.backward()\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step() \n",
    "        # add the training loss to the train loses\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # save checkpoint\n",
    "        checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "            \n",
    "        torch.save(checkpoint, f'{checkpoint_path}/checkpoint_{epoch}.pth.tar')\n",
    "        \n",
    "        # set the model to validation mode\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                x = x.reshape(x.shape[0], -1)\n",
    "                prediction = model(x)\n",
    "                val_loss += criterion(prediction, y).item()\n",
    "        \n",
    "        val_loss /= len(test_loader)  # Average validation loss\n",
    "        val_losses.append(val_loss)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "print(\"Training and validation completed.\")"
   ],
   "id": "38cdf4e768e82238",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_path = \"../models/simple_nn.pth\"",
   "id": "4d92d99aae8d4ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), model_path)"
   ],
   "id": "661eb788ea0caa96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ],
   "id": "cd3ac71c1488cf74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = np.arange(1, len(train_losses) + 1)",
   "id": "32aceae9377a6254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, val_losses, label=\"Validation Loss\", color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\" Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "8f5a4c0eca1cab9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the training\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, train_losses, label=\"Training Loss\", color='blue')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "68d6ae94b006cb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the training and validation loss \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, train_losses, label=\"Training Loss\", color='blue')\n",
    "plt.plot(x, val_losses, label=\"Validation Loss\", color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "1f767d53d79863f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check for the accuracy of the model\n",
    "def check_accuracy(loader, trained_model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    trained_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            pred_scores = trained_model(x)\n",
    "            _, predictions = pred_scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100}\")\n",
    "    print(f\"Accuracy: {float(num_correct)/float(num_samples)*100}\")"
   ],
   "id": "f4feb78d705fe673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "check_accuracy(test_loader, model)",
   "id": "e4ca2d18d8f5cc1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "db7b3aab64e6335f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
