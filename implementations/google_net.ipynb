{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        out_channels,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "    \n",
    "    \n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channel,\n",
    "        out_1x1,\n",
    "        red_3x3,\n",
    "        out_3x3,\n",
    "        red_5x5,\n",
    "        out_5x5,\n",
    "        out_1x1pool,\n",
    "    ) -> None:\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        \n",
    "        self.branch1 = ConvBlock(in_channel, out_1x1, kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_channel, red_3x3, kernel_size=1),\n",
    "            ConvBlock(red_3x3, out_3x3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_channel, red_5x5, kernel_size=1),\n",
    "            ConvBlock(red_5x5, out_5x5, kernel_size=5, stride=1, padding=2),\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_channel, out_1x1pool, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([\n",
    "            self.branch1(x),\n",
    "            self.branch2(x),\n",
    "            self.branch3(x),\n",
    "            self.branch4(x),\n",
    "        ], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, in_channels:int=3, num_classes:int=1000) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=64, \n",
    "            kernel_size=(7,7), \n",
    "            stride=(2,2), \n",
    "            padding=(3,3),\n",
    "        )\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = ConvBlock(\n",
    "            in_channels=64,\n",
    "            out_channels=192,\n",
    "            kernel_size=(3,3),\n",
    "            stride=(1,1),\n",
    "            padding=(1,1),\n",
    "        )\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # in_channel -> out_1x1 -> red_3x3 -> out_3x3 -> red_5x5 -> out_5x5 -> out_1x1pool,\n",
    "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "model = GoogleNet(in_channels=3, num_classes=1000).to(device)\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         ConvBlock-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      "         ConvBlock-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
      "             ReLU-13           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 96, 28, 28]          18,528\n",
      "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
      "             ReLU-17           [-1, 96, 28, 28]               0\n",
      "        ConvBlock-18           [-1, 96, 28, 28]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]         110,720\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-22          [-1, 128, 28, 28]               0\n",
      "           Conv2d-23           [-1, 16, 28, 28]           3,088\n",
      "      BatchNorm2d-24           [-1, 16, 28, 28]              32\n",
      "             ReLU-25           [-1, 16, 28, 28]               0\n",
      "        ConvBlock-26           [-1, 16, 28, 28]               0\n",
      "           Conv2d-27           [-1, 32, 28, 28]          12,832\n",
      "      BatchNorm2d-28           [-1, 32, 28, 28]              64\n",
      "             ReLU-29           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-30           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-31          [-1, 192, 28, 28]               0\n",
      "           Conv2d-32           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-33           [-1, 32, 28, 28]              64\n",
      "             ReLU-34           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-35           [-1, 32, 28, 28]               0\n",
      "   InceptionBlock-36          [-1, 256, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "             ReLU-39          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-40          [-1, 128, 28, 28]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
      "             ReLU-43          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 192, 28, 28]         221,376\n",
      "      BatchNorm2d-46          [-1, 192, 28, 28]             384\n",
      "             ReLU-47          [-1, 192, 28, 28]               0\n",
      "        ConvBlock-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
      "             ReLU-51           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-52           [-1, 32, 28, 28]               0\n",
      "           Conv2d-53           [-1, 96, 28, 28]          76,896\n",
      "      BatchNorm2d-54           [-1, 96, 28, 28]             192\n",
      "             ReLU-55           [-1, 96, 28, 28]               0\n",
      "        ConvBlock-56           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-57          [-1, 256, 28, 28]               0\n",
      "           Conv2d-58           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-59           [-1, 64, 28, 28]             128\n",
      "             ReLU-60           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-61           [-1, 64, 28, 28]               0\n",
      "   InceptionBlock-62          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-63          [-1, 480, 14, 14]               0\n",
      "           Conv2d-64          [-1, 192, 14, 14]          92,352\n",
      "      BatchNorm2d-65          [-1, 192, 14, 14]             384\n",
      "             ReLU-66          [-1, 192, 14, 14]               0\n",
      "        ConvBlock-67          [-1, 192, 14, 14]               0\n",
      "           Conv2d-68           [-1, 96, 14, 14]          46,176\n",
      "      BatchNorm2d-69           [-1, 96, 14, 14]             192\n",
      "             ReLU-70           [-1, 96, 14, 14]               0\n",
      "        ConvBlock-71           [-1, 96, 14, 14]               0\n",
      "           Conv2d-72          [-1, 208, 14, 14]         179,920\n",
      "      BatchNorm2d-73          [-1, 208, 14, 14]             416\n",
      "             ReLU-74          [-1, 208, 14, 14]               0\n",
      "        ConvBlock-75          [-1, 208, 14, 14]               0\n",
      "           Conv2d-76           [-1, 16, 14, 14]           7,696\n",
      "      BatchNorm2d-77           [-1, 16, 14, 14]              32\n",
      "             ReLU-78           [-1, 16, 14, 14]               0\n",
      "        ConvBlock-79           [-1, 16, 14, 14]               0\n",
      "           Conv2d-80           [-1, 48, 14, 14]          19,248\n",
      "      BatchNorm2d-81           [-1, 48, 14, 14]              96\n",
      "             ReLU-82           [-1, 48, 14, 14]               0\n",
      "        ConvBlock-83           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-84          [-1, 480, 14, 14]               0\n",
      "           Conv2d-85           [-1, 64, 14, 14]          30,784\n",
      "      BatchNorm2d-86           [-1, 64, 14, 14]             128\n",
      "             ReLU-87           [-1, 64, 14, 14]               0\n",
      "        ConvBlock-88           [-1, 64, 14, 14]               0\n",
      "   InceptionBlock-89          [-1, 512, 14, 14]               0\n",
      "           Conv2d-90          [-1, 160, 14, 14]          82,080\n",
      "      BatchNorm2d-91          [-1, 160, 14, 14]             320\n",
      "             ReLU-92          [-1, 160, 14, 14]               0\n",
      "        ConvBlock-93          [-1, 160, 14, 14]               0\n",
      "           Conv2d-94          [-1, 112, 14, 14]          57,456\n",
      "      BatchNorm2d-95          [-1, 112, 14, 14]             224\n",
      "             ReLU-96          [-1, 112, 14, 14]               0\n",
      "        ConvBlock-97          [-1, 112, 14, 14]               0\n",
      "           Conv2d-98          [-1, 224, 14, 14]         226,016\n",
      "      BatchNorm2d-99          [-1, 224, 14, 14]             448\n",
      "            ReLU-100          [-1, 224, 14, 14]               0\n",
      "       ConvBlock-101          [-1, 224, 14, 14]               0\n",
      "          Conv2d-102           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-103           [-1, 24, 14, 14]              48\n",
      "            ReLU-104           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-105           [-1, 24, 14, 14]               0\n",
      "          Conv2d-106           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-107           [-1, 64, 14, 14]             128\n",
      "            ReLU-108           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-109           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-110          [-1, 512, 14, 14]               0\n",
      "          Conv2d-111           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-112           [-1, 64, 14, 14]             128\n",
      "            ReLU-113           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-114           [-1, 64, 14, 14]               0\n",
      "  InceptionBlock-115          [-1, 512, 14, 14]               0\n",
      "          Conv2d-116          [-1, 128, 14, 14]          65,664\n",
      "     BatchNorm2d-117          [-1, 128, 14, 14]             256\n",
      "            ReLU-118          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-119          [-1, 128, 14, 14]               0\n",
      "          Conv2d-120          [-1, 128, 14, 14]          65,664\n",
      "     BatchNorm2d-121          [-1, 128, 14, 14]             256\n",
      "            ReLU-122          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-123          [-1, 128, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         295,168\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "       ConvBlock-127          [-1, 256, 14, 14]               0\n",
      "          Conv2d-128           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-129           [-1, 24, 14, 14]              48\n",
      "            ReLU-130           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-131           [-1, 24, 14, 14]               0\n",
      "          Conv2d-132           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-133           [-1, 64, 14, 14]             128\n",
      "            ReLU-134           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-135           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-136          [-1, 512, 14, 14]               0\n",
      "          Conv2d-137           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-138           [-1, 64, 14, 14]             128\n",
      "            ReLU-139           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-140           [-1, 64, 14, 14]               0\n",
      "  InceptionBlock-141          [-1, 512, 14, 14]               0\n",
      "          Conv2d-142          [-1, 112, 14, 14]          57,456\n",
      "     BatchNorm2d-143          [-1, 112, 14, 14]             224\n",
      "            ReLU-144          [-1, 112, 14, 14]               0\n",
      "       ConvBlock-145          [-1, 112, 14, 14]               0\n",
      "          Conv2d-146          [-1, 144, 14, 14]          73,872\n",
      "     BatchNorm2d-147          [-1, 144, 14, 14]             288\n",
      "            ReLU-148          [-1, 144, 14, 14]               0\n",
      "       ConvBlock-149          [-1, 144, 14, 14]               0\n",
      "          Conv2d-150          [-1, 288, 14, 14]         373,536\n",
      "     BatchNorm2d-151          [-1, 288, 14, 14]             576\n",
      "            ReLU-152          [-1, 288, 14, 14]               0\n",
      "       ConvBlock-153          [-1, 288, 14, 14]               0\n",
      "          Conv2d-154           [-1, 32, 14, 14]          16,416\n",
      "     BatchNorm2d-155           [-1, 32, 14, 14]              64\n",
      "            ReLU-156           [-1, 32, 14, 14]               0\n",
      "       ConvBlock-157           [-1, 32, 14, 14]               0\n",
      "          Conv2d-158           [-1, 64, 14, 14]          51,264\n",
      "     BatchNorm2d-159           [-1, 64, 14, 14]             128\n",
      "            ReLU-160           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-161           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-162          [-1, 512, 14, 14]               0\n",
      "          Conv2d-163           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-164           [-1, 64, 14, 14]             128\n",
      "            ReLU-165           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-166           [-1, 64, 14, 14]               0\n",
      "  InceptionBlock-167          [-1, 528, 14, 14]               0\n",
      "          Conv2d-168          [-1, 256, 14, 14]         135,424\n",
      "     BatchNorm2d-169          [-1, 256, 14, 14]             512\n",
      "            ReLU-170          [-1, 256, 14, 14]               0\n",
      "       ConvBlock-171          [-1, 256, 14, 14]               0\n",
      "          Conv2d-172          [-1, 160, 14, 14]          84,640\n",
      "     BatchNorm2d-173          [-1, 160, 14, 14]             320\n",
      "            ReLU-174          [-1, 160, 14, 14]               0\n",
      "       ConvBlock-175          [-1, 160, 14, 14]               0\n",
      "          Conv2d-176          [-1, 320, 14, 14]         461,120\n",
      "     BatchNorm2d-177          [-1, 320, 14, 14]             640\n",
      "            ReLU-178          [-1, 320, 14, 14]               0\n",
      "       ConvBlock-179          [-1, 320, 14, 14]               0\n",
      "          Conv2d-180           [-1, 32, 14, 14]          16,928\n",
      "     BatchNorm2d-181           [-1, 32, 14, 14]              64\n",
      "            ReLU-182           [-1, 32, 14, 14]               0\n",
      "       ConvBlock-183           [-1, 32, 14, 14]               0\n",
      "          Conv2d-184          [-1, 128, 14, 14]         102,528\n",
      "     BatchNorm2d-185          [-1, 128, 14, 14]             256\n",
      "            ReLU-186          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-187          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-188          [-1, 528, 14, 14]               0\n",
      "          Conv2d-189          [-1, 128, 14, 14]          67,712\n",
      "     BatchNorm2d-190          [-1, 128, 14, 14]             256\n",
      "            ReLU-191          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-192          [-1, 128, 14, 14]               0\n",
      "  InceptionBlock-193          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-194            [-1, 832, 7, 7]               0\n",
      "          Conv2d-195            [-1, 256, 7, 7]         213,248\n",
      "     BatchNorm2d-196            [-1, 256, 7, 7]             512\n",
      "            ReLU-197            [-1, 256, 7, 7]               0\n",
      "       ConvBlock-198            [-1, 256, 7, 7]               0\n",
      "          Conv2d-199            [-1, 160, 7, 7]         133,280\n",
      "     BatchNorm2d-200            [-1, 160, 7, 7]             320\n",
      "            ReLU-201            [-1, 160, 7, 7]               0\n",
      "       ConvBlock-202            [-1, 160, 7, 7]               0\n",
      "          Conv2d-203            [-1, 320, 7, 7]         461,120\n",
      "     BatchNorm2d-204            [-1, 320, 7, 7]             640\n",
      "            ReLU-205            [-1, 320, 7, 7]               0\n",
      "       ConvBlock-206            [-1, 320, 7, 7]               0\n",
      "          Conv2d-207             [-1, 32, 7, 7]          26,656\n",
      "     BatchNorm2d-208             [-1, 32, 7, 7]              64\n",
      "            ReLU-209             [-1, 32, 7, 7]               0\n",
      "       ConvBlock-210             [-1, 32, 7, 7]               0\n",
      "          Conv2d-211            [-1, 128, 7, 7]         102,528\n",
      "     BatchNorm2d-212            [-1, 128, 7, 7]             256\n",
      "            ReLU-213            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-214            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-215            [-1, 832, 7, 7]               0\n",
      "          Conv2d-216            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-217            [-1, 128, 7, 7]             256\n",
      "            ReLU-218            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-219            [-1, 128, 7, 7]               0\n",
      "  InceptionBlock-220            [-1, 832, 7, 7]               0\n",
      "          Conv2d-221            [-1, 384, 7, 7]         319,872\n",
      "     BatchNorm2d-222            [-1, 384, 7, 7]             768\n",
      "            ReLU-223            [-1, 384, 7, 7]               0\n",
      "       ConvBlock-224            [-1, 384, 7, 7]               0\n",
      "          Conv2d-225            [-1, 192, 7, 7]         159,936\n",
      "     BatchNorm2d-226            [-1, 192, 7, 7]             384\n",
      "            ReLU-227            [-1, 192, 7, 7]               0\n",
      "       ConvBlock-228            [-1, 192, 7, 7]               0\n",
      "          Conv2d-229            [-1, 384, 7, 7]         663,936\n",
      "     BatchNorm2d-230            [-1, 384, 7, 7]             768\n",
      "            ReLU-231            [-1, 384, 7, 7]               0\n",
      "       ConvBlock-232            [-1, 384, 7, 7]               0\n",
      "          Conv2d-233             [-1, 48, 7, 7]          39,984\n",
      "     BatchNorm2d-234             [-1, 48, 7, 7]              96\n",
      "            ReLU-235             [-1, 48, 7, 7]               0\n",
      "       ConvBlock-236             [-1, 48, 7, 7]               0\n",
      "          Conv2d-237            [-1, 128, 7, 7]         153,728\n",
      "     BatchNorm2d-238            [-1, 128, 7, 7]             256\n",
      "            ReLU-239            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-240            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-241            [-1, 832, 7, 7]               0\n",
      "          Conv2d-242            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-243            [-1, 128, 7, 7]             256\n",
      "            ReLU-244            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-245            [-1, 128, 7, 7]               0\n",
      "  InceptionBlock-246           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-247           [-1, 1024, 1, 1]               0\n",
      "         Dropout-248                 [-1, 1024]               0\n",
      "          Linear-249                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 7,008,824\n",
      "Trainable params: 7,008,824\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 112.59\n",
      "Params size (MB): 26.74\n",
      "Estimated Total Size (MB): 139.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
